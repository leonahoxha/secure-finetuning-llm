# Secure Fine-Tuning of LLMs via Encrypted Parameter Deltas

This repository contains the full implementation of the masterâ€™s thesis  
**"In-Memory Fine-Tuning of LLMs via Encrypted Parameter Deltas"**  
by **Leona Hoxha**, Constructor University, 2025.

---

## Project Overview

This project introduces a secure, memory-resident fine-tuning pipeline for large language models. Rather than saving fine-tuned weights to disk, the system:

- Tracks only modified tensors using backward hooks
- Computes parameter-level deltas and encrypts them with AES-CBC + HMAC-SHA256
- Stores encrypted patches in anonymous `mmap` memory regions (not on disk)
- Applies patches in RAM at inference time only when a valid decryption key is provided

This design provides:

- **Leakage resistance**
- **Fine-grained access control**
- **No persistent sensitive data**
- **Secure modular model customization**

---

## ðŸ—‚ï¸ Repository Structure

```text
.
â”œâ”€â”€ config/
â”‚   â””â”€â”€ train_base.py              # Config file for base model training
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chicago/
â”‚   â”‚   â”œâ”€â”€ prepare_chicago.py     # Tokenize Chicago CSV into Q/A format
â”‚   â”‚   â”œâ”€â”€ validate_chicago.py    # Validate tokenized Q/A examples
â”‚   â”‚   â”œâ”€â”€ chicago_employees.csv
â”‚   â”‚   â””â”€â”€ bin/                   # train.bin, val.bin, meta.pkl
â”‚   â””â”€â”€ openwebtext_toy/
â”‚       â”œâ”€â”€ prepare.py             # Tokenize OpenWebText filtered by economic keywords
â”‚       â”œâ”€â”€ validate.py            # Validate OpenWebText tokenization
â”‚       â””â”€â”€ bin/                   # train.bin, val.bin, meta.pkl
â”‚
â”œâ”€â”€ train.py                       # General training loop (resume, DDP, AMP)
â”œâ”€â”€ finetune_encrypt_memmap.py     # Core logic for secure delta tracking and patching
â”œâ”€â”€ model.py                        # GPT model (copied from NanoGPT, unmodified)
â”œâ”€â”€ configurator.py                 # Minimal config loader (from NanoGPT)
â”‚
â”œâ”€â”€ out/                            # Stores model checkpoints (e.g. final.pt)
â”‚
â”œâ”€â”€ test_pipeline/                 # Evaluation scripts
â”‚   â”œâ”€â”€ test_prompts.py            # Samples test prompts from bin files
â”‚   â”œâ”€â”€ test_prompt_robustness.py  # Evaluates response consistency to paraphrased prompts
â”‚   â”œâ”€â”€ leakage_test.py            # Checks base model leakage on fine-tuned prompts
â”‚   â”œâ”€â”€ decrypt_unit_test.py       # Unit test: AES/HMAC encryption correctness
â”‚   â””â”€â”€ decrypt_failure_test.py    # Tests failure when wrong key is used
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ inspect_ckpt.py            # Analyze model parameters and delta sizes
â”‚   â””â”€â”€ plot.py                    # Visualization scripts for loss or results
```

---

## Reproduction Steps

### 1. Train the base model
```bash
python train.py train_base.py
```

### 2. Fine-tune with encrypted delta patching
```bash
KEY=$(python3 -c "import os,binascii; print(binascii.hexlify(os.urandom(32)).decode())")
python finetune_encrypt_memmap.py \
  --base_ckpt out/base/final.pt \
  --data_dir data/chicago/bin \
  --additional_iters 1000 \
  --key $KEY \
  --prompt_file prompt.txt
```

### 3. Run evaluation and security tests
```bash
python test_pipeline/decrypt_failure_test.py
python test_pipeline/decrypt_unit_test.py
python test_pipeline/leakage_test.py --base_ckpt out/base/final.pt --prompt_file test_pipeline/test_prompts.txt
python test_pipeline/test_prompt_robustness.py --base_ckpt out/base/final.pt --data_dir data/chicago/bin --key $KEY
```

---

## Datasets Used

- [City of Chicago Employee Salaries](https://data.cityofchicago.org/)
- [OpenWebText Corpus](https://skylion007.github.io/OpenWebTextCorpus/)

Tokenized and anonymized versions are located under `data/chicago/bin/` and `data/openwebtext_toy/bin/`.

---

## Thesis Summary

> Hoxha, Leona. *In-Memory Fine-Tuning of LLMs via Encrypted Parameter Deltas*.  
> Masterâ€™s Thesis, Constructor University, 2025.

The proposed system enables encrypted, key-controlled model adaptation in RAM without modifying or persisting sensitive weights. This approach offers a novel direction for secure, modular LLM customization.

---

## License

- All original code: **MIT License**
- `model.py`, `configurator.py`: from [NanoGPT](https://github.com/karpathy/nanoGPT) (MIT License)

---

## Contact

**Leona Hoxha**  
leonahxh@gmail.com
lhoxha@constructor.university
```